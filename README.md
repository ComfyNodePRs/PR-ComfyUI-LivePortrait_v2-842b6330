# ComfyUI-LivePortrait_v2
## ðŸ”¥ Updates
ComfyUI nodes for LivePortrait, We support animal image driven mode and regional control for Comfyui!!!
We have developed animal expression-driven nodes for ComfyUI that have the same effect as the source code.
## Introduction 
This repo, named ComfyUI-LivePortrait_v2, thanks to paper LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control.
We developed a custom_node for Liveportrait_v2 that enables flexible use on Comfyui to drive animal image-based emoji generation from videos.
## Getting Started
### 1. Clone the code and prepare the environment 
```bash
git clone https://github.com/VangengLab/ComfyUI-LivePortrait_v2.git
cd ComfyUI-LivePortrait_v2
```
In this node, we need dependencies related to XPose. Specifically, it needs to be configured and prepared according to the instructions on https://github.com/KwaiVGI/LivePortrait. The cuda version is preferably 12.1.

or you can refer to my environment on https://github.com/VangengLab/Comfyui_Liveportrait_v3/edit/main/README.md
## Download pretrained weights

refer to https://github.com/VangengLab/Comfyui_Liveportrait_v3/edit/main/README.md
this repo will tell you all details about pretrained weights
